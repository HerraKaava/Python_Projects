{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67b938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc345a9e",
   "metadata": {},
   "source": [
    "Regarding the notation used\n",
    "\n",
    "- $\\pi^{(i)} \\rightarrow \\,$ distribution corresponding to time step $\\, i; \\,$ $\\, \\pi^{(i)} = [P(X_i = 0) \\quad P(X_i = 1) \\quad P(X_i = 2) \\quad \\dots \\quad P(X_i = r)]. \\,$\n",
    "- $\\pi \\rightarrow \\,$ stationary distribution.\n",
    "- $\\pi_i \\rightarrow \\,$ long-run probability of being in state $\\, i \\,$ in the stationary distribution; $\\, \\pi_i = \\underset{k \\rightarrow \\infty}{\\text{lim}} P(X_k = i), \\,$ where $\\, k \\,$ is the number of steps taken (i.e., the time step index). For example, if $\\, k= 1 \\, \\text{million}, \\,$ then $\\, \\pi_i \\,$ is the probability that the Markov chain is in state $\\, i \\,$ at time step $\\, 1 \\, \\text{million}. \\,$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca1465",
   "metadata": {},
   "source": [
    "<h2>Task 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029acc3",
   "metadata": {},
   "source": [
    "**(a)** \n",
    "\n",
    "$$ P =\n",
    "\\begin{bmatrix} \n",
    "0.3 & 0.5 & 0.2 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.6 & 0.2 & 0.2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ce81b",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "Let $\\, X_0 = 1. \\,$ This means that the initial (probability) distribution is $\\, \\pi^{(0)} = [1Â \\quad 0 \\quad 0]. \\,$\n",
    "\n",
    "Hence the distribution of $\\, X_1 \\,$ is $\\, \\pi^{(1)} = \\pi^{(0)} P \\,$ and the distribution of $\\, X_2 \\,$ is $\\, \\pi^{(2)} = \\pi^{(1)} P. \\,$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66c8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([0.3, 0.5, 0.2, 0.3, 0.4, 0.3, 0.6, 0.2, 0.2]).reshape(3,3)\n",
    "pi0 = np.array([1, 0, 0])[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6be2dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.5, 0.2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The distribution of X1\n",
    "pi0 @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2cbd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36, 0.39, 0.25]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The distribution of X2\n",
    "(pi0 @ P) @ P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8d84e",
   "metadata": {},
   "source": [
    "**(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f743369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distr(n, pi, P):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n: number of steps to take\n",
    "        pi: initial (probability) distribution of each state\n",
    "        P: transition matrix\n",
    "    \"\"\"\n",
    "    for i in range(n):\n",
    "        pi = pi @ P\n",
    "    return pi.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83292b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_distr = stationary_distr(n=1000000, pi=pi0, P=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652731eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37168142, 0.38938053, 0.23893805])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_distr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c652d",
   "metadata": {},
   "source": [
    "**(d)**\n",
    "\n",
    "A Markov chain is said to be *time reversible* if\n",
    "\n",
    "$$ \\large\\pi_i P_{ij} = \\pi_j P_{ji} \\quad \\quad \\forall i,j \\in \\mathbb{S} $$\n",
    "\n",
    "where $\\, \\pi \\,$ is the stationary distribution of the Markov chain and $\\, P \\,$ is the transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccde4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reversibility(P, pi):\n",
    "    forward = np.zeros(P.size)\n",
    "    backward = np.zeros(P.size)\n",
    "    k = 0\n",
    "    for i in range(P.shape[0]):\n",
    "        for j in range(P.shape[1]):\n",
    "            forward[k] = pi[i] * P[i,j]\n",
    "            backward[k] = pi[j] * P[j,i]\n",
    "            k += 1\n",
    "    return forward, backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21793d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11150442, 0.18584071, 0.07433628, 0.11681416, 0.15575221,\n",
       "        0.11681416, 0.14336283, 0.04778761, 0.04778761]),\n",
       " array([0.11150442, 0.11681416, 0.14336283, 0.18584071, 0.15575221,\n",
       "        0.04778761, 0.07433628, 0.11681416, 0.04778761]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_reversibility(P=P, pi=stat_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bceae6c",
   "metadata": {},
   "source": [
    "- We can clearly see that the Markov chain is not time reversible, since the condition mentioned above does not hold (if it did hold, the two arrays should contain the same elements on each index position)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be972eb",
   "metadata": {},
   "source": [
    "<h2>Task 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e922d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Markov_chain(s, n):\n",
    "    x = np.zeros(n)\n",
    "    x[0] = 0\n",
    "    for i in range(1, n):\n",
    "        x[i] = np.random.choice(a=np.array([0, x[i-1]+1]), size=1, replace=False, p=np.array([s, 1-s])).item()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e09866",
   "metadata": {},
   "outputs": [],
   "source": [
    "marko = generate_Markov_chain(s=1/2, n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3959b3",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf392a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical state space: [0.0, 14.0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Empirical state space: [{marko.min()}, {marko.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fe3f4",
   "metadata": {},
   "source": [
    "The theoretical state space $\\, \\mathbb{S} \\,$ consists of all nonnegative integers; $\\, \\mathbb{S} \\subseteq \\mathbb{Z}_{+}. \\,$ This is because at each step, the chain either resets to 0 (with probability $\\, s=0.5) \\,$ or increments by 1 (i.e., moves from $\\, i \\,$ to $\\, i+1) \\,$ (with probability $\\, 1-s = 0.5)).$\n",
    "\n",
    "In a Markov chain, the transition matrix is constructed in a way that each element $\\, P(i,j) \\,$ represents a probability of moving from state $\\, i \\,$ to state $\\, j. \\,$ Hence, for any current state $\\, i, \\,$ the probability of moving to state 0 is \n",
    "\n",
    "$$ P(i,0) = \\frac{1}{2}. $$\n",
    "\n",
    "Likewise, the probability of moving up one state is\n",
    "\n",
    "$$ P(i, i+1) = \\frac{1}{2}. $$\n",
    "\n",
    "For all the other states $\\, j \\ne 0, \\,$ $\\, j \\ne i+1, \\,$ we have\n",
    "\n",
    "$$ P(i, j) = 0. $$\n",
    "\n",
    "Putting these together we get\n",
    "\n",
    "$$\n",
    "P(i,j) =\n",
    "\\begin{cases} \n",
    "\\frac{1}{2}, & \\text{if} \\, \\, j=0 \\, \\, \\text{or} \\, \\, j=i+1 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91ee7f",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "$\\pi = [\\pi^{(0)} \\quad \\pi^{(1)} \\quad \\dots \\quad \\pi^{(n)}] \\quad \\Rightarrow \\quad$ these represent the long run proportions of that the Markov chain spends in each state $\\, \\pi^{(i)}. \\,$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee10a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0121e-01, 2.5099e-01, 1.2421e-01, 6.2210e-02, 3.0790e-02,\n",
       "       1.5310e-02, 7.5600e-03, 3.8500e-03, 1.9300e-03, 1.0200e-03,\n",
       "       4.6000e-04, 2.8000e-04, 1.2000e-04, 4.0000e-05, 2.0000e-05])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(marko, return_counts=True)[1] / marko.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56b20fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.501, 0.251, 0.124, 0.062, 0.031, 0.015, 0.008, 0.004, 0.002,\n",
       "       0.001, 0.   , 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(marko, return_counts=True)[1] / marko.size).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4385a",
   "metadata": {},
   "source": [
    "- The empirical distribution (above) is obtained by counting how many time each state appeared and dividing them by the total number of steps taken.\n",
    "\n",
    "More generally, the stationary distribution satisfies\n",
    "\n",
    "$$ \\pi_j = \\sum_{i} \\pi_i P(i, j) \\quad \\forall j. $$\n",
    "\n",
    "A more interesting inspection turns out to be again the theoretical distribution of $\\, \\pi, \\,$ when $\\, n \\rightarrow \\infty. \\,$\n",
    "\n",
    "$$ \\pi_0 = \\sum_{i=0}^{\\infty} \\pi_i P(i,0) = \\sum_{i=0}^{\\infty} \\pi_i \\cdot \\frac{1}{2} = \\frac{1}{2} \\sum_{i=0}^{\\infty} \\pi_i = \\frac{1}{2} \\cdot 1 = \\frac{1}{2}. $$\n",
    "\n",
    "where the last equality follows from the fact that $\\, \\pi \\,$ is a probability distribution, so its elements must sum up to 1.\n",
    "\n",
    "The Markov chain we're dealing with is defined such that the only way to arrive at state 1 is from state 0, and the only way to arrive to state 2 is from state 1, and so on.\n",
    "\n",
    "$$ \\pi_1 = \\pi_0 P(0,\\boldsymbol{1}) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4} $$\n",
    "\n",
    "$$ \\pi_2 = \\pi_1 P(1,\\boldsymbol{2}) = \\frac{1}{4} \\cdot \\frac{1}{2} = \\frac{1}{8} $$\n",
    "\n",
    "$$ \\pi_3 = \\pi_2 P(2,\\boldsymbol{3}) = \\frac{1}{8} \\cdot \\frac{1}{2} = \\frac{1}{16} $$\n",
    "\n",
    "and so on. We get a recursive formula for the stationary distribution\n",
    "\n",
    "$$ \\pi_i = \\left(\\frac{1}{2} \\right)^{i+1}, $$\n",
    "\n",
    "which matches the empirical result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa1cc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    return (1/2)**(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "684231d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.25\n",
      "0.125\n",
      "0.062\n",
      "0.031\n",
      "0.016\n",
      "0.008\n",
      "0.004\n",
      "0.002\n",
      "0.001\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# With recursion formula\n",
    "for i in range(len(np.unique(marko))):\n",
    "    print(np.round(f(i), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb7bfde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501\n",
      "0.251\n",
      "0.124\n",
      "0.062\n",
      "0.031\n",
      "0.015\n",
      "0.008\n",
      "0.004\n",
      "0.002\n",
      "0.001\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Empirical result\n",
    "for val in (np.unique(marko, return_counts=True)[1] / marko.size).round(3):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28658237",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "\n",
    "We'll use the stationary condition once again\n",
    "\n",
    "$$ \\pi_j = \\sum_{i} \\pi_i P(i, j) \\quad \\forall j. $$\n",
    "\n",
    "The only way to get to state $\\, j \\ge 1 \\,$ is from $\\, j-1, \\,$ and this happens with a probability of $\\, s-1. \\,$ Hence we have\n",
    "\n",
    "$$ \\pi_1 = s (1-s) $$\n",
    "\n",
    "$$ \\pi_2 = \\pi_1 (1-s) = s (1-s) (1-s) $$\n",
    "\n",
    "$$ \\pi_3 = \\pi_2 (1-s) = s (1-s) (1-s) (1-s) $$\n",
    "\n",
    "and so on. Hence we get a recursive formula any element of the stationary distribution\n",
    "\n",
    "$$ \\pi_j = s (1-s)^j. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a90e9db",
   "metadata": {},
   "source": [
    "<h2>Task 3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe6ebc",
   "metadata": {},
   "source": [
    "- Let $\\, X = (X_1,...,X_n) \\,$ be our original sample. \n",
    "- A bootstrap sample $\\, X^j = (X_1^j,...,X_n^j) \\,$ is formed by drawing $\\, n \\,$ independent samples from $\\, X \\,$ with replacement. \n",
    "- Let $\\, Y^j = (Y_1^j,...,Y_n^j) \\,$ be a random vector that counts how many times each original observation $\\, X_i \\,$ appears in the bootstrap sample $\\, X^j. \\,$ Hence $\\, Y_i^j \\,$ indicates how many times $\\, X_i \\,$ is drawn (chosen) from $\\, n \\,$ draws in the bootstrap sample $\\, X^j. \\,$\n",
    "\n",
    "We will assume that all of the original data points $\\, X_1,...,X_n \\,$ are equally likely to be drawn. Hence, for $\\, n  \\,$ draws, each of the original data points $\\, X_1,...,X_n \\,$ are drawn with a probability of $\\, \\frac{1}{n}. \\,$ \n",
    "\n",
    "It is not hard to see when reading the first two sentences from [this](https://en.wikipedia.org/wiki/Multinomial_distribution) wikipedia page that\n",
    "\n",
    "$$ Y^j \\sim \\text{Multinomial} \\left(n, \\frac{1}{n}, \\frac{1}{n}, ..., \\frac{1}{n} \\right), $$\n",
    "\n",
    "where $\\, n \\,$ is the number of trials (draws) and $\\, \\frac{1}{n}, \\frac{1}{n}, ..., \\frac{1}{n} \\,$ are the probabilities of each event happening (i.e., the probability of drawing each of the original samples $\\, X_1,...,X_n).$\n",
    "\n",
    "Not sure what the latter question means. So if we generate $\\, b \\,$ bootstrap samples independently, each producing a random vector $\\, Y^j, \\, j=1,...,b, \\,$ then we will have $\\, b \\,$ i.i.d. samples from $\\, Y^j \\sim \\text{Multinomial} \\left(n, \\frac{1}{n}, \\frac{1}{n}, ..., \\frac{1}{n} \\right).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4040b",
   "metadata": {},
   "source": [
    "<h2>Task 4</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396fea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife(X):\n",
    "    n = X.shape[0]\n",
    "    jackknife_samples = np.zeros((n, n-1))\n",
    "    for i in range(n):\n",
    "        jackknife_samples[i, :] = np.delete(X, i)\n",
    "    return jackknife_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a13ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1,11)    # Some random data\n",
    "samples = jackknife(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c0c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d57f51",
   "metadata": {},
   "source": [
    "- So there is no randomness involved in the jackknife subsamples once we have the original data locked in (X).\n",
    "- At every iteration, we just leave one of the original data points out.\n",
    "\n",
    "Looking at the diagonal of the matrix above, we'll see that the count matrix $\\, Y \\,$ takes the following form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8bc579",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0]\n",
    "Y = np.ones((n, n))\n",
    "np.fill_diagonal(Y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e13249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eeeb7e",
   "metadata": {},
   "source": [
    "- As there is no randomness, this matrix is **deterministic**.\n",
    "- So I guess this is a [degenerate distribution](https://en.wikipedia.org/wiki/Degenerate_distribution), as it only supports a single point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
