{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca2371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import symbols, sqrt, integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e7c7",
   "metadata": {},
   "source": [
    "<h2>Task 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b195b14",
   "metadata": {},
   "source": [
    "<h3>Monte Carlo integration</h3>\n",
    "\n",
    "The average value of a (continuous) function $\\, f(x) \\,$ can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\bar{f} &= \\frac{1}{b - a} \\int_{a}^{b} f(x) \\, dx \\\\\n",
    "    (b - a) \\bar{f} &= \\int_{a}^{b} f(x) \\, dx \\\\\n",
    "    (b - a) \\frac{1}{n} \\sum_{i=1}^{n} f(x_i) &\\approx \\int_{a}^{b} f(x) \\, dx, \n",
    "\\end{align*}\n",
    "\n",
    "where $\\, x_i, \\, \\, i=1,...,n, \\,$ are random samples from $\\, \\text{Uniform}(a,b). \\,$ This is the key idea behind Monte Carlo integration. This approximation works due to the law of large numbers; the sum $\\, (b - a) \\frac{1}{n} \\sum_{i=1}^{n} f(x_i) \\,$ is the sample mean of $\\, f(x), \\,$ and it converges to the true mean as $\\, n \\rightarrow \\infty. \\,$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25e9c5",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a10bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_integral(a, b):\n",
    "    x = symbols('x')\n",
    "    f = sqrt(1 + (1 / (1 + x)))\n",
    "    integral = integrate(f, (x, a, b)).evalf()\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69463947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.30011842817113$"
      ],
      "text/plain": [
       "1.30011842817113"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_integral(a=0, b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0eb95",
   "metadata": {},
   "source": [
    "- So the integral is approximately equal to 1.30012.\n",
    "- Let's see how close we can get via Monte Carlo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96526053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_X(x):\n",
    "    return np.sqrt(1 + (1 / (1 + x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1d8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_integration(n, a=0, b=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        a: lower limit of integration\n",
    "        b: upper limit of integration\n",
    "        n: the number of random samples to draw from U(a,b)\n",
    "    \"\"\"\n",
    "    u = np.random.uniform(low=a, high=b, size=n)\n",
    "    MC_est = np.sum(f_X(u))\n",
    "    return (b-a) * (1/n) * MC_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cae1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10, Monte Carlo estimator: 1.29837\n",
      "n: 100, Monte Carlo estimator: 1.30252\n",
      "n: 1000, Monte Carlo estimator: 1.29858\n",
      "n: 10000, Monte Carlo estimator: 1.29964\n",
      "n: 100000, Monte Carlo estimator: 1.29998\n",
      "n: 1000000, Monte Carlo estimator: 1.30022\n"
     ]
    }
   ],
   "source": [
    "for n in [10, 100, 1000, 10000, 100000, 1000000]:\n",
    "    mc_est = monte_carlo_integration(n=n)\n",
    "    print(f'n: {n}, Monte Carlo estimator: {mc_est:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d53255",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86a447",
   "metadata": {},
   "source": [
    "Let $\\, \\mathcal{\\hat{I}} \\,$ be the MC estimate of the integral, and let $\\, \\mathcal{I} \\,$ be its true value. We want that (Chebysev's inequality)\n",
    "\n",
    "\\begin{equation*}\n",
    "    P(|\\mathcal{\\hat{I}} - \\mathcal{I}| < \\epsilon) \\ge 1 - \\frac{\\sigma^2}{\\epsilon^2} \\ge 0.99\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\, X_1,...,X_n \\overset{\\bot}{\\sim}\\text{Uniform}(0,1). \\,$ The MC estimate and its variance are\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathcal{\\hat{I}} = \\frac{1}{n} \\sum_{i=1}^{n} f(X_i)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\text{Var}(\\mathcal{\\hat{I}}) = \\text{Var} \\left(\\frac{1}{n} \\sum_{i=1}^{n} f(X_i) \\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\text{Var}(f(X_i)) = \\frac{1}{n} \\text{Var}(f(X))\n",
    "\\end{equation*}\n",
    "\n",
    "We note that the theoretical variance $\\, \\sigma^2 \\,$ can be replaced with the sample variance of the MC sample. Hence we have\n",
    "\n",
    "\\begin{align*}\n",
    "    1 - \\frac{\\sigma^2}{\\epsilon^2} &\\ge 0.99 \\\\\n",
    "    1 - \\frac{\\text{Var}(f(X))}{n \\, \\epsilon^2} &\\ge 0.99 \\\\\n",
    "    0.01 - \\frac{\\text{Var}(f(X))}{n \\, \\epsilon^2} &\\ge 0 \\\\\n",
    "    0.01 &\\ge \\frac{\\text{Var}(f(X))}{n \\, \\epsilon^2} \\\\\n",
    "    0.01 \\cdot n \\cdot \\epsilon^2 &\\ge \\text{Var}(f(X)) \\\\\n",
    "    n &\\ge \\frac{\\text{Var}(f(X))}{0.01 \\cdot \\epsilon^2}.\n",
    "\\end{align*}\n",
    "\n",
    "We are given that $\\, \\epsilon = 0.001, \\,$ so we finally have the required sample size:\n",
    "\n",
    "\\begin{equation*}\n",
    "    n \\ge \\frac{\\text{Var}(f(X))}{0.01 \\cdot 0.001^2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7f4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_fX(n):\n",
    "    u = np.random.uniform(low=0, high=1, size=n)\n",
    "    fu = f_X(u)\n",
    "    MC_estimator_var = np.var(fu, ddof=1)\n",
    "    return MC_estimator_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a134dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.002833616600076021)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_fX(n=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0e4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_fX2(n):\n",
    "    \"\"\"\n",
    "    Just confirming that the simplified version above gives the same result \n",
    "    as the formula provided in the lecture notes.\n",
    "    \"\"\"\n",
    "    u = np.random.uniform(low=0, high=1, size=n)\n",
    "    MC_est = np.sum(f_X(u)) * (1/n)\n",
    "    return (1/(n-1)) * np.sum((f_X(u) - MC_est)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60adf6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0028399843316707137)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_fX2(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b4ed900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def required_sample_size(s):\n",
    "    sample_size = int(np.ceil(s / (0.01 * 0.001**2)))\n",
    "    print(f'Required sample size: {sample_size}')\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e36c8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 283753\n"
     ]
    }
   ],
   "source": [
    "sample_size = required_sample_size(s=var_fX(n=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6828d1",
   "metadata": {},
   "source": [
    "<h2>Task 2</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910de41",
   "metadata": {},
   "source": [
    "Let \n",
    "\n",
    "$$\n",
    "p_{X}(x) =\n",
    "\\begin{cases} \n",
    "x & \\text{, } 0 < x \\le 1, \\\\\n",
    "2 - x & \\text{, } 1 < x \\le 2, \\\\\n",
    "0 & \\text{, else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Be the probability density function of a random variable $\\, X. \\,$ Our goal is to calculate the expectation\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{E}[f(X)] = \\int_{-\\infty}^{\\infty} f(X) \\, p_{X}(x) \\, dx = \\int_{0}^{2} f(X) \\, p_{X}(x) \\, dx\n",
    "\\end{equation*}\n",
    "\n",
    "we'll do this via 1) *Monte Carlo integration* and 2) *importance sampling*. For the importance sampling, we are given that the proposal distribution is $\\, X' \\sim \\text{Uniform}(0,2). \\,$ We are also given that $\\, f(X) = |1 - x|. \\,$\n",
    "\n",
    "In importance sampling, the expectation $\\, \\mathbb{E}[f(X)] \\,$ can be approximated as\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{E}_p[f(X)] = \\int_{\\mathbb{X}} f(x) \\, p_X(x) \\, dx = \\int_{\\mathbb{X}} f(x) \\, \\frac{p_X(x)} {q_{X'}(x)} \\, q_{X'}(x) \\, dx = \\mathbb{E}_q \\left[f(X) \\, \\frac{p_X(X)}{q_{X'}(X)} \\right] \\approx \\frac{1}{n} \\sum_{i=1}^{n} f(X_i) \\, \\frac{p_X(X_i)}{q_{X'}(X_i)}.\n",
    "\\end{equation*}\n",
    "\n",
    "$\\large p_X(x)$ \n",
    "- the target density \n",
    "- the distribution that we're interested in\n",
    "- we're computing $\\, \\mathbb{E}[f(X)] \\,$ assuming that $\\, X \\sim p_X \\,$\n",
    "\n",
    "$\\large q_{X'}(x)$ \n",
    "- the proposal density\n",
    "- a simpler distribution that we're generating samples from\n",
    "- we're using these samples to approximate $\\, \\mathbb{E}[f(X)], \\,$ assuming that $\\, X \\sim p_X \\,$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd57aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.abs(1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61caab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x):\n",
    "    \"\"\"\n",
    "    Target density p_X(x)\n",
    "    \"\"\"\n",
    "    return np.maximum(0, 1 - np.abs(1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4349c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(a, b):\n",
    "    \"\"\"\n",
    "    Proposal density q_X'(x)\n",
    "    \"\"\"\n",
    "    return 1 / (b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e87e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(n):\n",
    "    res = np.zeros(n)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        x = np.random.uniform(low=0.0, high=2.0, size=1)\n",
    "        y = np.random.uniform(low=0.0, high=2.0, size=1)\n",
    "        if y <= p(x):\n",
    "            res[i] = x.item()\n",
    "            i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74221489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_integration(n=1000):\n",
    "    X = rejection_sampling(n=n)\n",
    "    MC_estimate = np.mean(f(X))\n",
    "    print(f'E[f(X)] ≈ Q_n(f(X)) = {MC_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4d6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling(a=0, b=2, n=1000):\n",
    "    X = np.random.uniform(low=a, high=b, size=n)\n",
    "    print(f'E[f(X)] ≈ {np.mean(f(X) * (p(X) / q(a,b)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b035b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[f(X)] ≈ Q_n(f(X)) = 0.33446505010082955\n"
     ]
    }
   ],
   "source": [
    "MC_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b738c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[f(X)] ≈ 0.33280822153461653\n"
     ]
    }
   ],
   "source": [
    "importance_sampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25480a",
   "metadata": {},
   "source": [
    "Next, we'll compare which of the methods yields a smaller variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf191147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vars(a=0, b=2, n=1000):\n",
    "    # Monte Carlo\n",
    "    u = rejection_sampling(n=n)\n",
    "    fu = f(u)\n",
    "    var1 = np.var(fu, ddof=1)\n",
    "    \n",
    "    # Importance sampling\n",
    "    X = np.random.uniform(low=a, high=b, size=n)\n",
    "    Y = f(X) * (p(X) / q(a,b))\n",
    "    var2 = np.var(Y, ddof=1)\n",
    "    \n",
    "    return var1, var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10257f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.055458503142710565), np.float64(0.02261144461553514))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586b838",
   "metadata": {},
   "source": [
    "- Importance sampling yields a smaller variance probably due to the fact that the proposal distribution $\\, q_{X'}(x) \\,$ is well chosen and resembles the target distribution $\\, p_{X}(x). \\,$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c6964",
   "metadata": {},
   "source": [
    "<h2>Task 4</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b47d77",
   "metadata": {},
   "source": [
    "We'll approximate the integral\n",
    "\n",
    "$$ \\int_{0}^{1} e^{-x^2} dx \\approx 0.746824. $$\n",
    "\n",
    "using Monte Carlo integration.\n",
    "\n",
    "<h3>Regular Monte Carlo integration</h3>\n",
    "\n",
    "\\begin{align*}\n",
    "    \\int_{a}^{b} f(x) \\, dx \\approx (b-a) \\frac{1}{n} \\sum_{i=1}^{n} f(X_i).\n",
    "\\end{align*}\n",
    "\n",
    "<h3>Antithetic variates method</h3>\n",
    "\n",
    "First we draw $\\, n/2 \\,$ independent random variables from the uniform distribution: $\\, X_1,...X_{n/2} \\overset{\\bot}{\\sim} \\text{Uniform}(0,1). \\,$ Then we define a new random variable $\\, Y_i = 1 - X_i. \\,$ Our estimator is now:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\hat{\\mu}_A = \\frac{1}{n/2} \\sum_{i=1}^{n/2} \\frac{f(X_i) + f(Y_i)}{2} = \\frac{1}{n} \\sum_{i=1}^{n/2} (f(X_i) + f(Y_i)).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94585c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.exp(-x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c530e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_int(n, a=0, b=1):\n",
    "    x = np.random.uniform(low=a, high=b, size=n)\n",
    "    return (b-a) * np.mean(f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa4bf68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antithetic_variates_method(n, a=0, b=1):\n",
    "    X = np.random.uniform(low=a, high=b, size=n//2)\n",
    "    Y = 1 - X\n",
    "    return (1/n) * np.sum(f(X) + f(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f74498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_sd(n, m):\n",
    "    estimates = [MC_int(n=n) for _ in range(m)]\n",
    "    return np.std(estimates, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1b105f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antithetic_sd(n, m):\n",
    "    estimates = [antithetic_variates_method(n=n) for _ in range(m)]\n",
    "    return np.std(estimates, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04fa7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7467665664410794)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_int(n=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f27c712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7468596867693995)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antithetic_variates_method(n=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "858dd61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0006384018199759097)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_sd(n=100000, m=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b3a7167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.00012670032305264433)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antithetic_sd(n=100000, m=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ba991",
   "metadata": {},
   "source": [
    "- The antithetic variates method gives approximately 5 times smaller standard error (standard deviation).\n",
    "- I believe that this is due to the fact that $\\, X \\,$ and $\\, Y \\,$ are negatively correlated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
