{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7795d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e953f",
   "metadata": {},
   "source": [
    "Suppose that we have the following matrix of transition probabilities (see [Markov Chains](https://www.youtube.com/watch?v=i3AkTO9HLXo&t=4s))\n",
    "\n",
    "$$ P(x,y) =\n",
    "\\begin{bmatrix} \n",
    "0.2 & 0.6 & 0.2 \\\\\n",
    "0.3 & 0 & 0.7 \\\\\n",
    "0.5 & 0 & 0.5\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where the states are $\\, \\alpha, \\beta, \\gamma \\,$ ($\\alpha$ in 1st row, 1st col, $\\beta$ in 2nd row, 2nd col, $\\gamma$ in 3rd row, 3rd col).\n",
    "\n",
    "The probabilities of each state is denoted by a **row** vector $\\, \\pi. \\,$ \n",
    "\n",
    "Suppose that our initial state is $\\, X_0 = \\beta. \\,$ Then the initial (probability) distribution is $\\, \\pi^{(0)} = [0 \\quad 1 \\quad 0]. \\,$ This is because if $\\, X_0 = \\beta, \\,$ we know for sure that the system starts in state $\\beta$. So there is no uncertainty; it is a deterministic condition. If we were told that the initial state is random such that the probability of starting at each state is for example 0.3, 0.3, 0.4 for $\\, \\alpha, \\beta, \\gamma, \\,$ respectively, then the initial distribution would be $\\, \\pi^{(0)} = [0.3 \\quad 0.3 \\quad 0.4]. \\,$ \n",
    "\n",
    "The distribution of the next state $\\, X_1 \\,$ can be calculated with vector matrix multiplication\n",
    "\n",
    "$$ \\pi^{(1)} = \\pi^{(0)} P. $$\n",
    "\n",
    "Similarly, the distribution of $\\, X_2 \\,$ can be calculated as\n",
    "\n",
    "$$ \\pi^{(2)} = \\pi^{(1)} P $$\n",
    "\n",
    "and so on.\n",
    "\n",
    "(note that the notation $\\, \\pi^{(i)} \\,$ is used to denote the probability distribution of the *ith* state. This notation style is taken from [here](https://www.probabilitycourse.com/chapter11/11_2_3_probability_distributions.php))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e06424",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([0.2, 0.6, 0.2, 0.3, 0, 0.7, 0.5, 0, 0.5]).reshape(3,3)\n",
    "pi_0 = np.array([0, 1, 0])[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99061730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_1 = pi_0 @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3406c743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0. , 0.7]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa253fa",
   "metadata": {},
   "source": [
    "- Note that this first operation just picks the row corresponding to $\\, \\beta \\,$ from the transition matrix $\\, P(x,y). \\,$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74acee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_2 = pi_1 @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c848f2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41, 0.18, 0.41]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708878e9",
   "metadata": {},
   "source": [
    "Continuing to move up in the states will bring us to the stationary distribution (i.e., the probabilities of each state will converge to some constant) if the following conditions are satisfied\n",
    "\n",
    "**1**. Irreducibility: You can get from any state to any other state (possibly in multiple steps).\n",
    "    \n",
    "**2**. Aperiodicity: The chain doesn't get \"stuck\" in cycles; each state returns to itself at some irregular intervals.\n",
    "    \n",
    "**3**. Finite state space $\\, \\mathbb{S}: \\,$ The *state space* of a Markov chain is the set of all possible states the system can be in (in our example, the possible states are $\\, \\alpha, \\beta, \\gamma \\, \\rightarrow \\, \\mathbb{S} = \\{\\alpha, \\beta, \\gamma \\}).$\n",
    "\n",
    "If all these conditions hold, then regardless where we start $\\, (\\text{i.e., regardless of } X_0), \\,$ the (probability) distribution of $\\, X_n \\,$ will converge\n",
    "\n",
    "$$ \\underset{n \\rightarrow \\infty}{\\text{lim }} \\pi_n = \\pi $$\n",
    "\n",
    "where $\\, \\pi \\,$ is the **stationary distribution** of the Markov chain, and it satisfies\n",
    "\n",
    "$$ \\pi P = \\pi $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sum_{\\pi_i} \\pi_i = 1. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d1a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distr(n, pi, P):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n: the number of steps to take (i.e., the number of states to move forward)\n",
    "        pi: the initial (probability) distribution of each state\n",
    "        P: the transition matrix\n",
    "    \"\"\"\n",
    "    for i in range(n):\n",
    "        pi = pi @ P\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bd2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_distr = stationary_distr(n=1000000, pi=pi_0, P=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afebf449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35211268, 0.21126761, 0.43661972]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65a1968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999997)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_distr.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad4b78",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "A Markov chain is defined by\n",
    "\n",
    "**1. A state space**\n",
    "- A set of possible states $\\, \\mathbb{S} \\,$ (e.g., $\\alpha, \\beta, \\gamma).$\n",
    "    \n",
    "**2. A transition matrix P**\n",
    "- This gives the probabilities of moving between states; $\\, P = [p_{ij}], \\,$ where $\\, p_{ij} = P(X_{n+1} = j | X_{n} = i).$\n",
    "\n",
    "**3. An initial (probability) distribution $\\pi^{(0)}$**\n",
    "- The probability of starting in each state."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
